---
title: "Multivariante"
author: "Eduardo Montoro de la Cruz"
date: "2024-11-22"
output:
  html_document: default
  pdf_document: default
---
```{r}
library(summarytools)
library(ggpubr)
library(ggplot2)
library(factoextra)
library(scatterplot3d)
library(foreign)
# Package required to call 'scatterplot3d' function
library(scatterplot3d)
# Package required to call 'melt' function
library(reshape2)
# Package required to call 'mvn' function
library(MVN)
# Package required to call 'boxM' function
library(biotools)
# Package required to call 'partimat' function
library(klaR)
# Package required to call 'summarise' function
library(dplyr)
# Package required to call 'createDataPartition' function
library(caret)
primaria<-read.spss("Burnout_EBAP_20_22_IJERPH.sav", to.data.frame=TRUE)
#gestoras<-read.spss("Burnout_gestoras_15_22_JPM.sav", to.data.frame=TRUE)

```

```{r}
#primaria<-primaria[,-c(27,29,30)] #Eliminamos las columnas con muchos NAN y servicio2, que no aporta.
primaria<-primaria[,-25]
#Eliminamos la columna de Pacientes de 60 años por tener todo NA

primaria<-primaria[,-28]

#Eliminamos las columnas relacionadas con las preguntas.

primaria<-primaria[,1:28]



#Hacemos factores las columnas

primaria[, c("MBI_CE_Cat", "MBI_D_Cat","MBI_RP_Cat","Sexo","Servicio","Turno_Cat","Guardias","Puesto_trabajo","Estado_Civil_Cat","Num_hijos_Cat","Categoría","Provincia","Estado_Civil","Turno","Nombre","Gestíon","Ocupó_gestión")] <- lapply(primaria[, c("MBI_CE_Cat", "MBI_D_Cat","MBI_RP_Cat","Sexo","Servicio","Turno_Cat","Guardias","Puesto_trabajo","Estado_Civil_Cat","Num_hijos_Cat","Categoría","Provincia","Estado_Civil","Turno","Nombre","Gestíon","Ocupó_gestión")], as.factor)





```




```{r}
#Codificamos todo
#Para las respuestas Bajo medio alto se asigna el 1,2,3. 
cols_MBI=c("MBI_CE_Cat", "MBI_D_Cat","MBI_RP_Cat")
primaria[,cols_MBI]<-lapply(primaria[,cols_MBI],factor,level=c("Bajo","Medio","Alto"),labels=c(1,2,3))

#Para el numero de hijos asigno cada numero segun el numero de hijos

primaria$Num_hijos_Cat<-factor(primaria$Num_hijos_Cat,level=c("Sin hijos","Un hijo","Dos hijos","Familia Numerosa"),labels=c(0,1,2,3))

#Para las columnas con respuestas Hombre/Mujer, Casado/soltero, etc se asignan los numeros de menor a mayor por orden alfabetico.

primaria$Sexo<-factor(primaria$Sexo,level=c("Hombre","Mujer"),labels=c(1,2))

primaria$Servicio<-factor(primaria$Servicio,levels=sort(levels(primaria$Servicio)))

primaria$Turno_Cat<-factor(primaria$Turno_Cat,levels=sort(levels(primaria$Turno_Cat)))

primaria$Guardias<-factor(primaria$Guardias,levels=sort(levels(primaria$Guardias)))

primaria$Puesto_trabajo<-factor(primaria$Puesto_trabajo,levels=sort(levels(primaria$Puesto_trabajo)))

primaria$Estado_Civil_Cat<-factor(primaria$Estado_Civil_Cat,levels=sort(levels(primaria$Estado_Civil_Cat)))

primaria$Num_hijos_Cat<-factor(primaria$Num_hijos_Cat,levels=sort(levels(primaria$Num_hijos_Cat)))

primaria$Categoría<-factor(primaria$Categoría,levels=sort(levels(primaria$Categoría)))

primaria$Provincia<-factor(primaria$Provincia,levels=sort(levels(primaria$Provincia)))

primaria$Estado_Civil<-factor(primaria$Estado_Civil,levels=sort(levels(primaria$Estado_Civil)))

primaria$Turno<-factor(primaria$Turno,levels=sort(levels(primaria$Turno)))

primaria$Nombre<-factor(primaria$Nombre,levels=sort(levels(primaria$Nombre)))

primaria$Gestíon<-factor(primaria$Gestíon, levels=sort(levels(primaria$Gestíon)))

primaria$Ocupó_gestión<-factor(primaria$Ocupó_gestión, levels=sort(levels(primaria$Ocupó_gestión)))

```


```{r}
# Funcion para arreglar los datos NA de tiempo de gestion en concreto
not_available_tiempogestion<-function(data,na.rm=F){
data[is.na(data)]<- 0
data
}
# Funcion por si alguien NA en gestion o ocupo gestion
not_available_gestion<-function(data,na.rm=F){
data[is.na(data)]<- 'No' #¿Aqui por que no funciona si pongo la mode(data) o median(data)??
data
}


moda <- function(x) {
  ux <- unique(na.omit(x))  # Valores únicos, eliminando NA
  ux[which.max(tabulate(match(x, ux)))]  # El valor con mayor frecuencia
}

not_available_hijos <- function(data) {
  moda_valor <- moda(data)  # Calculamos la moda
  data[is.na(data)] <- moda_valor  # Reemplazamos NA con la moda
  return(data)  # Devolvemos la columna modificada
}
primaria$Num_hijos_Cat <- not_available_hijos(primaria$Num_hijos_Cat)
primaria$Numero_hijos <- not_available_hijos(primaria$Numero_hijos)


cols_tgestion<-c('Tiempo_gestión','Tiempo_ocupó_gestión')
cols_gestion<-c('Gestíon','Ocupó_gestión')
#primaria[,cols_gestion]

#Ahora tocaria aplicar estas funciones a las columnas adecuadas

primaria[,cols_tgestion]<-lapply(primaria[,cols_tgestion],not_available_tiempogestion)
primaria[,cols_gestion]<-lapply(primaria[,cols_gestion],not_available_gestion)

#Ahora cambiar los valores no nulos que hayan puesto que no, en un Si
primaria[primaria$Tiempo_gestión!=0,'Gestíon'] <-'Sí'

#primaria[,c(cols_gestion,cols_tgestion)]

```

Estudiamos graficas varias de distintas variables. Empezamos por las variables cuantitativas

```{r}
#Variables cuantitativas

descr(primaria$Neur_NEOFFI)
p1<-ggplot(primaria,aes(x=Neur_NEOFFI))+geom_density()+
labs(title = "Funcion de densidad del neuroticismo",x="Neuroticismo",y="Valores")
p2<-ggplot(primaria,aes(x=Neur_NEOFFI))+geom_histogram()+
labs(title = "Histograma del neuroticismo",x="Neuroticismo",y="Valores")
p3<-ggplot(primaria,aes(x=Neur_NEOFFI))+
geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2)+
coord_flip()+labs(title = "Boxplot del neuroticismo",x="Valores",y="")

ggarrange(p1,p2,p3, nrow=1, common.legend = FALSE)
```


```{r}
descr(primaria$Amab_NEOFFI)
p1<-ggplot(primaria,aes(x=Amab_NEOFFI))+geom_density()+
labs(title = "Funcion de densidad de la amabilidad",x="Amabilidad",y="Valores")
p2<-ggplot(primaria,aes(x=Amab_NEOFFI))+geom_histogram()+
labs(title = "Histograma de la amabilidad",x="Amabilidad",y="Valores")
p3<-ggplot(primaria,aes(x=Amab_NEOFFI))+
geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2)+
coord_flip()+labs(title = "Boxplot de la amabilidad",x="Valores",y="")

ggarrange(p1,p2,p3, nrow=1, common.legend = FALSE)

```

```{r}
descr(primaria$Resp_NEOFFI)
p1<-ggplot(primaria,aes(x=Resp_NEOFFI))+geom_density()+
labs(title = "Funcion de densidad de la responsabilidad",x="Responsabilidad",y="Valores")
p2<-ggplot(primaria,aes(x=Resp_NEOFFI))+geom_histogram()+
labs(title = "Histograma de la responsabilidad",x="Responsabilidad",y="Valores")
p3<-ggplot(primaria,aes(x=Resp_NEOFFI))+
geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2)+
coord_flip()+labs(title = "Boxplot de la responsabilidad",x="Valores",y="")

ggarrange(p1,p2,p3, nrow=1, common.legend = FALSE)



``` 

```{r}
descr(primaria$Extrav_NEOFFI)
p1<-ggplot(primaria,aes(x=Extrav_NEOFFI))+geom_density()+
labs(title = "Funcion de densidad de la extraversión",x="Extraversión",y="Valores")
p2<-ggplot(primaria,aes(x=Extrav_NEOFFI))+geom_histogram()+
labs(title = "Histograma de la extraversión",x="Extraversión",y="Valores")
p3<-ggplot(primaria,aes(x=Extrav_NEOFFI))+
geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2)+
coord_flip()+labs(title = "Boxplot de la extraversión",x="Valores",y="")

ggarrange(p1,p2,p3, nrow=1, common.legend = FALSE)


```

```{r}
descr(primaria$Apert_NEOFFI)
p1<-ggplot(primaria,aes(x=Apert_NEOFFI))+geom_density()+
labs(title = "Funcion de densidad de la apertura a nuevas experiencias",x="Nuevas experiencias",y="Valores")
p2<-ggplot(primaria,aes(x=Apert_NEOFFI))+geom_histogram()+
labs(title = "Histograma de la apertura a nuevas experiencias",x="Nuevas experiencias",y="Valores")
p3<-ggplot(primaria,aes(x=Apert_NEOFFI))+
geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2)+
coord_flip()+labs(title = "Boxplot de la apertura a nuevas experiencias",x="Valores",y="")

ggarrange(p1,p2,p3, nrow=1, common.legend = FALSE)

```
Vamos ahora a por las cualitativas

```{r}
primaria$MBI_CE_Cat <- factor(primaria$MBI_CE_Cat,levels=c(1,2,3),labels=c("Bajo","Medio","Alto"))
freq(primaria$MBI_CE_Cat)
p1<-ggplot(primaria,aes(x=factor(1),fill=MBI_CE_Cat))+geom_bar()+
coord_polar("y")+labs(x="MBI CE",y="Valores")
p2<-ggplot(primaria,aes(x=factor(1),fill=MBI_CE_Cat))+geom_bar()+
labs(x="MBI CE ",y="Valores")
ggarrange(p1,p2,nrow = 1,ncol=2, common.legend = TRUE)

```

```{r}
primaria$MBI_D_Cat <- factor(primaria$MBI_D_Cat,levels=c(1,2,3),labels=c("Bajo","Medio","Alto"))
freq(primaria$MBI_D_Cat)
p1<-ggplot(primaria,aes(x=factor(1),fill=MBI_D_Cat))+geom_bar()+
coord_polar("y")+labs(x="MBI D",y="Valores")
p2<-ggplot(primaria,aes(x=factor(1),fill=MBI_D_Cat))+geom_bar()+
labs(x="MBI D",y="Valores")
ggarrange(p1,p2,nrow = 1,ncol=2, common.legend = TRUE)


```

```{r}
primaria$MBI_RP_Cat <- factor(primaria$MBI_RP_Cat,levels=c(1,2,3),labels=c("Bajo","Medio","Alto"))
freq(primaria$MBI_RP_Cat)
p1<-ggplot(primaria,aes(x=factor(1),fill=MBI_RP_Cat))+geom_bar()+
coord_polar("y")+labs(x="MBI RP",y="Valores")
p2<-ggplot(primaria,aes(x=factor(1),fill=MBI_RP_Cat))+geom_bar()+
labs(x="MBI RP",y="Valores")
ggarrange(p1,p2,nrow = 1,ncol=2, common.legend = TRUE)



```

```{r}
attach(primaria)
#Primero para MBI CE 
p1 <- ggplot(data = primaria, aes(x = Neur_NEOFFI, fill = MBI_CE_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p2 <- ggplot(data = primaria, aes(x = Amab_NEOFFI, fill = MBI_CE_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p3 <- ggplot(data = primaria, aes(x = Resp_NEOFFI, fill = MBI_CE_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p4 <- ggplot(data = primaria, aes(x = Extrav_NEOFFI, fill = MBI_CE_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p5 <- ggplot(data = primaria, aes(x = Apert_NEOFFI, fill = MBI_CE_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)

ggarrange(p1, p2, p3,p4,p5, nrow = 3,ncol = 2, common.legend = TRUE, top = "Clas. individual según el MBI_CE")

#Ahora para MBI D

p1 <- ggplot(data = primaria, aes(x = Neur_NEOFFI, fill = MBI_D_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p2 <- ggplot(data = primaria, aes(x = Amab_NEOFFI, fill = MBI_D_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p3 <- ggplot(data = primaria, aes(x = Resp_NEOFFI, fill = MBI_D_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p4 <- ggplot(data = primaria, aes(x = Extrav_NEOFFI, fill = MBI_D_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p5 <- ggplot(data = primaria, aes(x = Apert_NEOFFI, fill = MBI_D_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)

ggarrange(p1, p2, p3,p4,p5, nrow = 3,ncol = 2, common.legend = TRUE, top= "Clas. individual para el MBI_D")

#Finalmente para MBI RP
p1 <- ggplot(data = primaria, aes(x = Neur_NEOFFI, fill = MBI_RP_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p2 <- ggplot(data = primaria, aes(x = Amab_NEOFFI, fill = MBI_RP_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p3 <- ggplot(data = primaria, aes(x = Resp_NEOFFI, fill = MBI_RP_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p4 <- ggplot(data = primaria, aes(x = Extrav_NEOFFI, fill = MBI_RP_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p5 <- ggplot(data = primaria, aes(x = Apert_NEOFFI, fill = MBI_RP_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)

ggarrange(p1, p2, p3,p4,p5, nrow = 3,ncol = 2, common.legend = TRUE, top= "Clas. individual para el MBI_RP")

```
```{r}
pairs(x = primaria[, c("Neur_NEOFFI","Amab_NEOFFI","Resp_NEOFFI","Extrav_NEOFFI","Apert_NEOFFI")],
col = c("green", "red", "purple")[primaria$MBI_RP_Cat], pch = 19)
```
```{r}
pairs(x = primaria[, c("Neur_NEOFFI","Amab_NEOFFI","Resp_NEOFFI","Extrav_NEOFFI","Apert_NEOFFI")],
col = c("green", "red", "purple")[primaria$MBI_D_Cat], pch = 19)
```

```{r}
pairs(x = primaria[, c("Neur_NEOFFI","Amab_NEOFFI","Resp_NEOFFI","Extrav_NEOFFI","Apert_NEOFFI")],
col = c("green", "red", "purple")[primaria$MBI_CE_Cat], pch = 19)
```
Tridimensional caso 1 para cansancio emocional
```{r}
scatterplot3d(Neur_NEOFFI, Resp_NEOFFI, Amab_NEOFFI,
color = c("green", "red", "purple")[MBI_CE_Cat], pch = 19,
grid = TRUE, xlab = "Neuroticismo", ylab = "Responsabilidad",
zlab = "Amabilidad", angle = 65, cex.axis = 0.6)
legend("topleft",
bty = "n", cex = 0.8,
title = "Cansancio Emocional",
c("1-Bajo", "2-Medio", "3-Alto"), fill = c("green", "red", "purple"))
```
Tridimensional caso 2 para cansancio emocional
```{r}
scatterplot3d(Neur_NEOFFI, Extrav_NEOFFI, Amab_NEOFFI,
color = c("green", "red", "purple")[MBI_CE_Cat], pch = 19,
grid = TRUE, xlab = "Neuroticismo", ylab = "Extraversión",
zlab = "Amabilidad", angle = 65, cex.axis = 0.6)
legend("topleft",
bty = "n", cex = 0.8,
title = "Cansancio Emocional",
c("1-Bajo", "2-Medio", "3-Alto"), fill = c("green", "red", "purple"))
```

Tridimensional Depersonalización
```{r}
scatterplot3d(Neur_NEOFFI, Resp_NEOFFI, Amab_NEOFFI,
color = c("green", "red", "purple")[MBI_CE_Cat], pch = 19,
grid = TRUE, xlab = "Neuroticismo", ylab = "Responsabilidad",
zlab = "Amabilidad", angle = 65, cex.axis = 0.6)
legend("topleft",
bty = "n", cex = 0.8,
title = "Depersonalización",
c("1-Bajo", "2-Medio", "3-Alto"), fill = c("green", "red", "purple"))
```

Tridimensional Responsabilidad
```{r}
scatterplot3d(Extrav_NEOFFI, Resp_NEOFFI, Amab_NEOFFI,
color = c("green", "red", "purple")[MBI_CE_Cat], pch = 19,
grid = TRUE, xlab = "Extraversión", ylab = "Responsabilidad",
zlab = "Amabilidad", angle = 65, cex.axis = 0.6)
legend("topleft",
bty = "n", cex = 0.8,
title = "Responsabilidad",
c("1-Bajo", "2-Medio", "3-Alto"), fill = c("green", "red", "purple"))
```
Vamos edu y yo a ver la normalidad

```{r}
par(mfcol = c(3, 5))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:3) {
i0 <- levels(primaria$MBI_CE_Cat)[i]
x <- primaria[primaria$MBI_CE_Cat == i0, j0]
hist(x, proba = T, col = grey(0.8), main = paste("MBI_CE_Cat", i0), xlab = j0)
lines(x0, dnorm(x0, mean(x), sd(x)), col = "blue", lwd = 2)
}
}

par(mfcol = c(3, 5))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:3) {
i0 <- levels(primaria$MBI_D_Cat)[i]
x <- primaria[primaria$MBI_D_Cat == i0, j0]
hist(x, proba = T, col = grey(0.8), main = paste("MBI_D_Cat", i0), xlab = j0)
lines(x0, dnorm(x0, mean(x), sd(x)), col = "blue", lwd = 2)
}
}

par(mfcol = c(3, 5))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:3) {
i0 <- levels(primaria$MBI_RP_Cat)[i]
x <- primaria[primaria$MBI_RP_Cat == i0, j0]
hist(x, proba = T, col = grey(0.8), main = paste("MBI_RP_Cat", i0), xlab = j0)
lines(x0, dnorm(x0, mean(x), sd(x)), col = "blue", lwd = 2)
}
}
```


Una vez hemos visto que las variables de la personalidad siguen distribuciones normales por tanto podemos proseguir con el analisis discriminatorio. 

```{r}

par(mfcol = c(3, 5))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:3) {
i0 <- levels(primaria$MBI_CE_Cat)[i]
x <- primaria[primaria$MBI_CE_Cat == i0, j0]
qqnorm(x, main = paste("MBI_CE_Cat", i0, j0), pch = 19, col = i + 1)
qqline(x)
}
}

par(mfcol = c(3, 5))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:3) {
i0 <- levels(primaria$MBI_D_Cat)[i]
x <- primaria[primaria$MBI_D_Cat == i0, j0]
qqnorm(x, main = paste("MBI_D_Cat", i0, j0), pch = 19, col = i + 1)
qqline(x)
}
}


par(mfcol = c(3, 5))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:3) {
i0 <- levels(primaria$MBI_RP_Cat)[i]
x <- primaria[primaria$MBI_RP_Cat == i0, j0]
qqnorm(x, main = paste("MBI_RP_Cat", i0, j0), pch = 19, col = i + 1)
qqline(x)
}
}
```

A mas lineal, mas normal

```{r}
primaria_tidy <- melt(primaria[,c(1:8)], value.name = "value")
aggregate( value ~ MBI_CE_Cat + variable, data = primaria_tidy,
FUN = function(x){shapiro.test(x)$p.value})

primaria_tidy <- melt(primaria[,c(1:8)], value.name = "value")
aggregate( value ~ MBI_D_Cat + variable, data = primaria_tidy,
FUN = function(x){shapiro.test(x)$p.value})

primaria_tidy <- melt(primaria[,c(1:8)], value.name = "value")
aggregate( value ~ MBI_RP_Cat + variable, data = primaria_tidy,
FUN = function(x){shapiro.test(x)$p.value})
```

```{r}
#Hacemos analisis outliers aunque pensamos que no varia mucho
#outliers <- mvn(data = primaria[,c(4:8)], mvnTest = "hz", multivariateOutlierMethod = "quan")

#Test de Royston
royston_test <- mvn(data = primaria[,c(4:8)], mvnTest = "royston", multivariatePlot = "qq")
royston_test$multivariateNormality
#Test de HZ
hz_test <- mvn(data = primaria[,c(4:8)], mvnTest = "hz")
hz_test$multivariateNormality
```

```{r}
#Tenemos 5 predictores (las 5 de personalidad) asi que hacemos el Box M test
boxM(data = primaria[, 4:8], grouping = primaria[, 1])
boxM(data = primaria[, 4:8], grouping = primaria[, 2])
boxM(data = primaria[, 4:8], grouping = primaria[, 3])
```

Como todas son mayores que p=0.001, rechazamos la heterogeneidad de la varianza.

Aplicamos al fin el discriminante lineal

```{r}
modelo_ldaCE <- lda(formula = MBI_CE_Cat ~ Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI,data = primaria)
modelo_ldaCE

modelo_ldaD <- lda(formula = MBI_D_Cat ~ Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI,data = primaria)
modelo_ldaD

modelo_ldaRP <- lda(formula = MBI_RP_Cat ~ Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI,data = primaria)
modelo_ldaRP
```


```{r}
modelo_ldaCECateg <- lda(formula = MBI_CE_Cat ~ Edad+Sexo+Antigüedad_profesión+Antigüedad_puesto+Turno_Cat+Guardias+Puesto_trabajo+Estado_Civil_Cat+Gestíon+Tiempo_gestión+Ocupó_gestión+Tiempo_ocupó_gestión,data = primaria)
modelo_ldaCECateg
#OJO, ME ESTA DANDO UN ERROR AL METER COMO VARIABLE EL NUMERO DE HIJOS, ESTO SIGNIFICA QUE NO TIENE IMPORTANCIA EL NUMERO DE HIJOS RESPECTO A LA VARIABLE CE, YA QUE DICE QUE ES CONSTANTE.

modelo_ldaDCateg <- lda(formula = MBI_D_Cat ~ Edad+Sexo+Antigüedad_profesión+Antigüedad_puesto+Turno_Cat+Guardias+Puesto_trabajo+Estado_Civil_Cat+Gestíon+Tiempo_gestión+Ocupó_gestión+Tiempo_ocupó_gestión,data = primaria)
modelo_ldaDCateg
#ME OCURRE LO MISMO EN ESTA CON EL NUM DE HIJOS

modelo_ldaRPCateg <- lda(formula = MBI_RP_Cat ~ Edad+Sexo+Antigüedad_profesión+Antigüedad_puesto+Turno_Cat+Guardias+Puesto_trabajo+Estado_Civil_Cat+Gestíon+Tiempo_gestión+Ocupó_gestión+Tiempo_ocupó_gestión,data = primaria)
modelo_ldaRPCateg
#Y EN ESTA IGUAL, POR ESO NO APARECE EN NINGUNA, PORQUE ME DA EL ERROR Y TENGO QUE QUITARLAS.



```

De esto obtenemos el modelo lineal de clasificacion discriminante tal que, dados los datos, nos dice a que grupo dentro del MBI, desconozco si lo que obtenemos de LD1 y LD2 son doos probabilidades lineales o una matriz, entiendo que una matriz.




Por ver el total por curiosidad

```{r}
modelo_ldaCETotal <- lda(formula = MBI_CE_Cat ~ Neur_NEOFFI+Amab_NEOFFI+Extrav_NEOFFI+Resp_NEOFFI+Apert_NEOFFI+Edad+Sexo+Antigüedad_profesión+Antigüedad_puesto+Turno_Cat+Guardias+Puesto_trabajo+Estado_Civil_Cat+Gestíon+Tiempo_gestión+Ocupó_gestión+Tiempo_ocupó_gestión,data = primaria)
modelo_ldaCETotal
# Extraer la matriz de coeficientes (scaling) y convertirla en data.frame
scaling_df <- as.data.frame(modelo_ldaCETotal$scaling)

# Añadir los nombres de las variables como columna
scaling_df$Variable <- rownames(scaling_df)

# Reordenar el data.frame por los valores de LD1 de mayor a menor
scaling_ordered <- scaling_df[order(scaling_df$LD1, decreasing = TRUE), ]

# Mostrar la tabla ordenada
print(scaling_ordered)


modelo_ldaDTotal <- lda(formula = MBI_D_Cat ~ Neur_NEOFFI+Amab_NEOFFI+Extrav_NEOFFI+Resp_NEOFFI+Apert_NEOFFI+Edad+Sexo+Antigüedad_profesión+Antigüedad_puesto+Turno_Cat+Guardias+Puesto_trabajo+Estado_Civil_Cat+Gestíon+Tiempo_gestión+Ocupó_gestión+Tiempo_ocupó_gestión,data = primaria)

# Extraer la matriz de coeficientes (scaling) y convertirla en data.frame
scaling_df <- as.data.frame(modelo_ldaDTotal$scaling)

# Añadir los nombres de las variables como columna
scaling_df$Variable <- rownames(scaling_df)

# Reordenar el data.frame por los valores de LD1 de mayor a menor
scaling_ordered <- scaling_df[order(scaling_df$LD1, decreasing = TRUE), ]

# Mostrar la tabla ordenada
print(scaling_ordered)



modelo_ldaRPTotal <- lda(formula = MBI_RP_Cat ~ Neur_NEOFFI+Amab_NEOFFI+Extrav_NEOFFI+Resp_NEOFFI+Apert_NEOFFI+Edad+Sexo+Antigüedad_profesión+Antigüedad_puesto+Turno_Cat+Guardias+Puesto_trabajo+Estado_Civil_Cat+Gestíon+Tiempo_gestión+Ocupó_gestión+Tiempo_ocupó_gestión,data = primaria)

# Extraer la matriz de coeficientes (scaling) y convertirla en data.frame
scaling_df <- as.data.frame(modelo_ldaRPTotal$scaling)

# Añadir los nombres de las variables como columna
scaling_df$Variable <- rownames(scaling_df)

# Reordenar el data.frame por los valores de LD1 de mayor a menor
scaling_ordered <- scaling_df[order(scaling_df$LD1, decreasing = TRUE), ]

# Mostrar la tabla ordenada
print(scaling_ordered)


```
Volvemos a lo que estabamos haciendo 

```{r}
modelo_ldaCE <- lda(formula = MBI_CE_Cat ~ Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI,data = primaria)
modelo_ldaCE

modelo_ldaD <- lda(formula = MBI_D_Cat ~ Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI,data = primaria)
modelo_ldaD

modelo_ldaRP <- lda(formula = MBI_RP_Cat ~ Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI,data = primaria)
modelo_ldaRP
```


```{r}
nuev_obs<-data.frame(Neur_NEOFFI=42, Amab_NEOFFI=37,Resp_NEOFFI=85,Extrav_NEOFFI=12,Apert_NEOFFI=52)
predict(object=modelo_ldaCE,newdata=nuev_obs)


predict(object=modelo_ldaD,newdata=nuev_obs)


predict(object=modelo_ldaRP,newdata=nuev_obs)
```

De modo que nuestro sujeto inventado tendria un CE Alto y unos D y RP medios
Deberiamos haber utilizado un training set y un test set por lados distintos, pero realmente es igual.


Siguiendo con el tratamiento veamos la matriz de confusion: Nos da la eficiencia(predichos/verdaderos) y pureza (predichos/total predicciones) (esto ultimo es, si buscasemos Altos, seria predichos altos/predichos altos medios y bajos).

```{r}
pred <- predict(modelo_ldaCE, dimen = 2)
confusionmatrix(primaria$MBI_CE_Cat, pred$class)
training_errorCE<-mean(primaria$MBI_CE_Cat != pred$class) * 100
paste("training_errorCE=", training_errorCE, "%")


pred <- predict(modelo_ldaD, dimen = 2)
confusionmatrix(primaria$MBI_D_Cat, pred$class)
training_errorD<-mean(primaria$MBI_D_Cat != pred$class) * 100
paste("training_errorD=", training_errorD, "%")


pred <- predict(modelo_ldaRP, dimen = 2)
confusionmatrix(primaria$MBI_RP_Cat, pred$class)
training_errorRP<-mean(primaria$MBI_RP_Cat != pred$class) * 100
paste("training_errorRP=", training_errorRP, "%")


pred <- predict(modelo_ldaCETotal, dimen = 2)
confusionmatrix(primaria$MBI_CE_Cat[1:250], pred$class)
training_errorCE<-mean(primaria$MBI_CE_Cat != pred$class) * 100
paste("training_errorCE=", training_errorCE, "%")



pred <- predict(modelo_ldaDTotal, dimen = 2)
confusionmatrix(primaria$MBI_D_Cat[1:250], pred$class)
training_errorD<-mean(primaria$MBI_D_Cat != pred$class) * 100
paste("training_errorD=", training_errorD, "%")


pred <- predict(modelo_ldaRPTotal, dimen = 2)
confusionmatrix(primaria$MBI_RP_Cat[1:250], pred$class)
training_errorRP<-mean(primaria$MBI_RP_Cat != pred$class) * 100
paste("training_errorRP=", training_errorRP, "%")

```
A pesar de haber hecho a parte los totales para ver si las variables categoricas influyen, estos modelos tienen un error mucho mayor que el 50%, entonces no deberiamos de hacerles caso para nada.

Vemos que el modelo lda se equivoca una barbaridad.

```{r}
partimat(MBI_CE_Cat ~Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI ,
data = primaria, method = "lda", prec = 200,
image.colors = c("green", "orange","blue"),
col.mean = "yellow",nplots.vert =1, nplots.hor=5, main= "Partition plot for MBI_CE")

partimat(MBI_D_Cat ~Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI ,
data = primaria, method = "lda", prec = 200,
image.colors = c("green", "orange","blue"),
col.mean = "yellow",nplots.vert =1, nplots.hor=5,main= "Partition plot for MBI_D")

partimat(MBI_RP_Cat ~Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI ,
data = primaria, method = "lda", prec = 200,
image.colors = c("green", "orange","blue"),
col.mean = "yellow",nplots.vert =1, nplots.hor=5,main= "Partition plot for MBI_RP")
```
Las dos primeras son para el CE, las dos siguientes para el D y las dos ultimas para el RP

No necesitamos hacer analisis quadratico porque tenemos varianza homogenea.


Hacemos parejas de variables: bajo-medio, medio-alto
```{r}
#Cansancio Emocional
MBI_CE_BM=vector() #Vector Bajo-Medio
MBI_CE_BM=primaria[primaria$MBI_CE_Cat!="Alto",]
MBI_CE_BM$MBI_CE_Cat <- factor(MBI_CE_BM$MBI_CE_Cat, levels = c("Bajo", "Medio"), labels = c(0, 1))

MBI_CE_MA=vector()#Vector Medio-Alto
MBI_CE_MA=primaria[primaria$MBI_CE_Cat!="Bajo",]
MBI_CE_MA$MBI_CE_Cat <- factor(MBI_CE_MA$MBI_CE_Cat, levels = c("Medio", "Alto"), labels = c(0, 1))

#Realización Personal
MBI_RP_BM=vector() #Vector Bajo-Medio
MBI_RP_BM=primaria[primaria$MBI_RP_Cat!="Alto",]
MBI_RP_BM$MBI_RP_Cat <- factor(MBI_RP_BM$MBI_RP_Cat, levels = c("Bajo", "Medio"), labels = c(0, 1))

MBI_RP_MA=vector()#Vector Medio-Alto
MBI_RP_MA=primaria[primaria$MBI_RP_Cat!="Bajo",]
MBI_RP_MA$MBI_RP_Cat <- factor(MBI_RP_MA$MBI_RP_Cat, levels = c("Medio", "Alto"), labels = c(0, 1))

#Despersonalización
MBI_D_BM=vector() #Vector Bajo-Medio
MBI_D_BM=primaria[primaria$MBI_D_Cat!="Alto",]
MBI_D_BM$MBI_D_Cat <- factor(MBI_D_BM$MBI_D_Cat, levels = c("Bajo", "Medio"), labels = c(0, 1))

MBI_D_MA=vector()#Vector Medio-Alto
MBI_D_MA=primaria[primaria$MBI_D_Cat!="Bajo",]
MBI_D_MA$MBI_D_Cat <- factor(MBI_D_MA$MBI_D_Cat, levels = c("Medio", "Alto"), labels = c(0, 1))



```

Tras dicotomizar, separamos en medio alto las variables CE y D, ya que alto es cuando sufren burnout y bajo la RP.

```{r}
par(mfcol = c(3, 4))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:2) {
i0 <- levels(MBI_CE_MA$MBI_CE_Cat)[i]
x <- MBI_CE_MA[MBI_CE_MA$MBI_CE_Cat == i0, j0]
hist(x, proba = T, col = grey(0.8), main = paste("MBI_CE_MA", i0), xlab = j0)
lines(x0, dnorm(x0, mean(x), sd(x)), col = "blue", lwd = 2)
}
}

par(mfcol = c(3, 4))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:2) {
i0 <- levels(MBI_D_MA$MBI_D_Cat)[i]
x <- MBI_D_MA[MBI_D_MA$MBI_D_Cat == i0, j0]
hist(x, proba = T, col = grey(0.8), main = paste("MBI_D_MA", i0), xlab = j0)
lines(x0, dnorm(x0, mean(x), sd(x)), col = "blue", lwd = 2)
}
}

par(mfcol = c(3, 4))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:2) {
i0 <- levels(MBI_RP_BM$MBI_RP_Cat)[i]
x <- MBI_RP_BM[MBI_RP_BM$MBI_RP_Cat == i0, j0]
hist(x, proba = T, col = grey(0.8), main = paste("MBI_RP_MA", i0), xlab = j0)
lines(x0, dnorm(x0, mean(x), sd(x)), col = "blue", lwd = 2)
}
}
```


```{r}

par(mfcol = c(3, 5))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:2) {
i0 <- levels(MBI_CE_MA$MBI_CE_Cat)[i]
x <- MBI_CE_MA[MBI_CE_MA$MBI_CE_Cat == i0, j0]
qqnorm(x, main = paste("MBI_CE_MA", i0, j0), pch = 19, col = i + 1)
qqline(x)
}
}

par(mfcol = c(3, 5))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:2) {
i0 <- levels(MBI_D_MA$MBI_D_Cat)[i]
x <- MBI_D_MA[MBI_D_MA$MBI_D_Cat == i0, j0]
qqnorm(x, main = paste("MBI_D_MA", i0, j0), pch = 19, col = i + 1)
qqline(x)
}
}


par(mfcol = c(3, 5))
for (k in 4:8) {
j0 <- names(primaria)[k]
x0 <- seq(min(primaria[, k]), max(primaria[, k]), le = 50)
for (i in 1:2) {
i0 <- levels(MBI_RP_BM$MBI_RP_Cat)[i]
x <- MBI_RP_BM[MBI_RP_BM$MBI_RP_Cat == i0, j0]
qqnorm(x, main = paste("MBI_RP_Cat", i0, j0), pch = 19, col = i + 1)
qqline(x)
}
}


```


```{r}
outliers <- mvn(data = MBI_CE_MA[,c(4:8)], mvnTest = "hz", multivariateOutlierMethod = "quan")

outliers <- mvn(data = MBI_D_MA[,c(4:8)], mvnTest = "hz", multivariateOutlierMethod = "quan")

outliers <- mvn(data = MBI_RP_MA[,c(4:8)], mvnTest = "hz", multivariateOutlierMethod = "quan")

```



A mas lineal, mas normal

```{r}
primaria_tidy <- melt(MBI_CE_MA[,c(1:8)], value.name = "value")
aggregate( value ~ MBI_CE_Cat + variable, data = primaria_tidy,
FUN = function(x){shapiro.test(x)$p.value})

primaria_tidy <- melt(MBI_D_MA[,c(1:8)], value.name = "value")
aggregate( value ~ MBI_D_Cat + variable, data = primaria_tidy,
FUN = function(x){shapiro.test(x)$p.value})

primaria_tidy <- melt(MBI_RP_BM[,c(1:8)], value.name = "value")
aggregate( value ~ MBI_RP_Cat + variable, data = primaria_tidy,
FUN = function(x){shapiro.test(x)$p.value})
```

```{r}
#Hacemos analisis outliers aunque pensamos que no varia mucho
#outliers <- mvn(data = primaria[,c(4:8)], mvnTest = "hz", multivariateOutlierMethod = "quan")

#Test de Royston
royston_test <- mvn(data = MBI_CE_MA[,c(4:8)], mvnTest = "royston", multivariatePlot = "qq")
royston_test$multivariateNormality
#Test de HZ
hz_test <- mvn(data = MBI_CE_MA[,c(4:8)], mvnTest = "hz")
hz_test$multivariateNormality
```




```{r}
modelo_ldaCE_MA <- lda(formula = MBI_CE_Cat ~ Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI,data = MBI_CE_MA)
modelo_ldaCE_MA

modelo_ldaD_MA <- lda(formula = MBI_D_Cat ~ Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI,data = MBI_D_MA)
modelo_ldaD_MA

modelo_ldaRP_BM <- lda(formula = MBI_RP_Cat ~ Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI,data = MBI_RP_BM)
modelo_ldaRP_BM

```

```{r}
nuev_obs<-data.frame(Neur_NEOFFI=42, Amab_NEOFFI=37,Resp_NEOFFI=85,Extrav_NEOFFI=12,Apert_NEOFFI=52)
predict(object=modelo_ldaCE_MA,newdata=nuev_obs)


predict(object=modelo_ldaD_MA,newdata=nuev_obs)


predict(object=modelo_ldaRP_BM,newdata=nuev_obs)
```
```{r}
# Extraer la matriz de coeficientes (scaling) y convertirla en data.frame
scaling_df <- as.data.frame(modelo_ldaCE_MA$scaling)

# Añadir los nombres de las variables como columna
scaling_df$Variable <- rownames(scaling_df)

# Reordenar el data.frame por los valores de LD1 de mayor a menor
scaling_ordered <- scaling_df[order(abs(scaling_df$LD1), decreasing = TRUE), ]

# Mostrar la tabla ordenada
print(scaling_ordered)




# Extraer la matriz de coeficientes (scaling) y convertirla en data.frame
scaling_df <- as.data.frame(modelo_ldaD_MA$scaling)

# Añadir los nombres de las variables como columna
scaling_df$Variable <- rownames(scaling_df)

# Reordenar el data.frame por los valores de LD1 de mayor a menor
scaling_ordered <- scaling_df[order(abs(scaling_df$LD1), decreasing = TRUE), ]

# Mostrar la tabla ordenada
print(scaling_ordered)




# Extraer la matriz de coeficientes (scaling) y convertirla en data.frame
scaling_df <- as.data.frame(modelo_ldaRP_BM$scaling)

# Añadir los nombres de las variables como columna
scaling_df$Variable <- rownames(scaling_df)

# Reordenar el data.frame por los valores de LD1 de mayor a menor
scaling_ordered <- scaling_df[order(abs(scaling_df$LD1), decreasing = TRUE), ]

# Mostrar la tabla ordenada
print(scaling_ordered)
```

```{r}
pred <- predict(modelo_ldaCE_MA, dimen = 1)
confusionmatrix(MBI_CE_MA$MBI_CE_Cat, pred$class)
training_errorCE<-mean(MBI_CE_MA$MBI_CE_Cat != pred$class) * 100
paste("training_errorCE=", training_errorCE, "%")


pred <- predict(modelo_ldaD_MA, dimen = 1)
confusionmatrix(MBI_D_MA$MBI_D_Cat, pred$class)
training_errorD<-mean(MBI_D_MA$MBI_D_Cat != pred$class) * 100
paste("training_errorD=", training_errorD, "%")


pred <- predict(modelo_ldaRP_BM, dimen = 1)
confusionmatrix(MBI_RP_BM$MBI_RP_Cat, pred$class)
training_errorRP<-mean(MBI_RP_BM$MBI_RP_Cat != pred$class) * 100
paste("training_errorRP=", training_errorRP, "%")

```
```{r}

attach(primaria)
#Primero para MBI CE 
p1 <- ggplot(data = MBI_CE_MA, aes(x = Neur_NEOFFI, fill = MBI_CE_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p2 <- ggplot(data = MBI_CE_MA, aes(x = Amab_NEOFFI, fill = MBI_CE_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p3 <- ggplot(data = MBI_CE_MA, aes(x = Resp_NEOFFI, fill = MBI_CE_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p4 <- ggplot(data = MBI_CE_MA, aes(x = Extrav_NEOFFI, fill = MBI_CE_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p5 <- ggplot(data = MBI_CE_MA, aes(x = Apert_NEOFFI, fill = MBI_CE_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)

ggarrange(p1, p2, p3,p4,p5, nrow = 3,ncol = 2, common.legend = TRUE, top = "Clas. individual según el MBI_CE")

#Ahora para MBI D

p1 <- ggplot(data = MBI_D_MA, aes(x = Neur_NEOFFI, fill = MBI_D_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p2 <- ggplot(data = MBI_D_MA, aes(x = Amab_NEOFFI, fill = MBI_D_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p3 <- ggplot(data = MBI_D_MA, aes(x = Resp_NEOFFI, fill = MBI_D_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p4 <- ggplot(data = MBI_D_MA, aes(x = Extrav_NEOFFI, fill = MBI_D_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p5 <- ggplot(data = MBI_D_MA, aes(x = Apert_NEOFFI, fill = MBI_D_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)

ggarrange(p1, p2, p3,p4,p5, nrow = 3,ncol = 2, common.legend = TRUE, top= "Clas. individual para el MBI_D")

#Finalmente para MBI RP
p1 <- ggplot(data = MBI_RP_BM, aes(x = Neur_NEOFFI, fill = MBI_RP_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p2 <- ggplot(data = MBI_RP_BM, aes(x = Amab_NEOFFI, fill = MBI_RP_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p3 <- ggplot(data = MBI_RP_BM, aes(x = Resp_NEOFFI, fill = MBI_RP_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p4 <- ggplot(data = MBI_RP_BM, aes(x = Extrav_NEOFFI, fill = MBI_RP_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)
p5 <- ggplot(data = MBI_RP_BM, aes(x = Apert_NEOFFI, fill = MBI_RP_Cat)) +
geom_histogram(position = "identity", alpha = 0.5)

ggarrange(p1, p2, p3,p4,p5, nrow = 3,ncol = 2, common.legend = TRUE, top= "Clas. individual para el MBI_RP")
```


```{r}
pairs(x = MBI_CE_MA[, c("Neur_NEOFFI","Amab_NEOFFI","Resp_NEOFFI","Extrav_NEOFFI","Apert_NEOFFI")],
col = c("green", "red", "purple")[MBI_CE_MA$MBI_CE_Cat], pch = 19)

pairs(x = MBI_D_MA[, c("Neur_NEOFFI","Amab_NEOFFI","Resp_NEOFFI","Extrav_NEOFFI","Apert_NEOFFI")],
col = c("green", "red", "purple")[MBI_D_MA$MBI_D_Cat], pch = 19)

pairs(x = MBI_RP_BM[, c("Neur_NEOFFI","Amab_NEOFFI","Resp_NEOFFI","Extrav_NEOFFI","Apert_NEOFFI")],
col = c("green", "red", "purple")[MBI_RP_BM$MBI_RP_Cat], pch = 19)

```

```{r}
partimat(MBI_CE_Cat ~Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI ,
data = MBI_CE_MA, method = "lda", prec = 200,
image.colors = c("green","blue"),
col.mean = "yellow",nplots.vert =1, nplots.hor=5, main= "Partition plot for MBI_CE_MA")

partimat(MBI_D_Cat ~Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI ,
data = MBI_D_MA, method = "lda", prec = 200,
image.colors = c("green","blue"),
col.mean = "yellow",nplots.vert =1, nplots.hor=5,main= "Partition plot for MBI_D_MA")

partimat(MBI_RP_Cat ~Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI+ Extrav_NEOFFI+ Apert_NEOFFI ,
data = MBI_RP_BM, method = "lda", prec = 200,
image.colors = c("green","blue"),
col.mean = "yellow",nplots.vert =1, nplots.hor=5,main= "Partition plot for MBI_RP_BM")
```

En el caso del modelo LDA, este no proporciona el valor de los p-valores asociados a cada coeficiente.

En primer lugar se representaron los histogramas de las variables de  personalidad para cada uno de los síntomas del Burnout. Las variables que nos permitieron separar los valores altos de Cansancio Emocional y Depersonalización, y los valores bajos de realización personal serán buenos clasificadores.

Para Cansancio Emocional fueron Neuroticismo, Extraversión y Amabilidad, para Depersonalización fueron Neuroticismo Amabilidad y Responsabilidad y para Realización Personal fueron Amabilidad, Extraversión y Responsabilidad.

Una vez hecho esto, se realizaron las representaciones de puntos bivariadas y trivariadas, tomando como ternas de variables aquellas que separaron bien los valores sobre el histograma.

Al representar los histogramas univariantes y los gráficos qqplot, se observa que las variables siguen distribuciones normales. Además, al emplear el test de Shapiro-Wilk no se encuentran evidencias de falta de normalidad, pues en la mayoría de casos el p-valor es mayor que 0.05.

Al utilizar el test de Royston y el de Henze-Zirckler para la normalidad multivariante, se obtiene que los datos no siguen una normal multivariante.

En cuanto a la homogeneidad de la varianza, como se tienen múltiples predictores, se utiliza el text Box M. En todos los casos se tiene un p-valor por encima de 0.001, por lo que no se tienen evidencias para rechazar la hipótesis nula. (Que significa esto? interpretación.)

Aplicando el discriminante lineal a las variables de personalidad, se obtiene que en todos los casos que el primer discriminante lineal es mucho mayor que el segundo y, por tanto, tiene mucha más fuerza. Además, las variables con mayor valor (en valor absoluto) coinciden con las variables que mejor separaban sobre el histograma de frecuencias multivariante.

Al aplicar el discriminante lineal a todas las variables, obtenemos de nuevo que el LD1 es el que más fuerza tiene, siendo mucho mayor que LD2.

El modelo con las variables de personalidad se equivoca entre el 36% y el 45%. Este error es muy alto, por lo que no podemos emplear el modelo para predecir, pero sí que podemos confirmar cuáles son las variables más influyentes en el Burnout. Por otro lado, el error en el modelo al considerar la totalidad de las variables es aun mayor, equivocándose más de la mitad de las veces. De esta forma, descartamos el modelo obtenido al utilizar todas las variables.

Por último realizamos el modelo de nuevo, eliminando los valores bajos para Cansancio Emocional y Despersonalización, y los altos para Realización Personal. (Falta escribir más cosas de aquí :))

MODELO LOGIT 

A continuación, se realizará un modelo de regresión logística (logit) con el objetivo de analizar la relación entre las variables dependientes categóricas (Cansancio Emocional, Despersonalización y Realización Personal) y las variables independientes (Neuroticismo, Amabilidad, Responsabilidad, Extraversión y Apertura). Esto permitirá precedir qué rasgos de personalidad son más o menos relevantes en la explicación de los síntomas del Burnout.

En primer lugar, se obtendrán para cada uno de los síntomas del Burnout, los valores de los coeficientes estimados ($\beta_i$) del modelo. Estos coeficientes determinarán la influencia de cada una de las variables independientes en las odds logarítmicas de que un individuo pertenezca a una categoría específica de la variable dependiente. 

Si el coeficiente es positivo, un incremento en la variable independiente supone un incremento en la probabilidad de pertenecer al grupo de interés. Por el contrario, si el coefiente es negativo, un incremento en la variable independiente supone una disminución en la probabilidad de pertenecer al grupo de interés. El tamaño de los coeficientes indica la fuerza relativa con la que cada variable contribuye a la clasificación entre las categorías de la variable dependiente.


Comenzamos definiendo el modelo logístico para cada uno de los síntomas del Burnout y obteniendo sus coeficientes correspondientes.

Para el Cansancio Emocional:
```{r}
modelo_logitCE <- glm(MBI_CE_Cat ~Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI + Extrav_NEOFFI + Apert_NEOFFI, 
              family = binomial(link = "logit"), 
              data = MBI_CE_MA)

coeficientes1 <- coef(modelo_logitCE)
# Ordenar los coeficientes por valor absoluto
coef_ordenados1 <- coeficientes1[order(abs(coeficientes1), decreasing = TRUE)]

# Mostrar los coeficientes ordenados
print("Coeficientes beta ordenados por valor absoluto:")
print(coef_ordenados1)

```
Como puede observarse, el coeficiente con mayor valor absoluto se trata del asociado a la variable independiente Neuroticismo tomando un valor de $\beta$=0.09183424. Esto sugiere que el Neuroticismo es la variable con mayor fuerza a la hora de clasificar entre el Cansancio Emocional Medio y Alto.

Para la Despersonalización:
```{r}
modelo_logitD <- glm(MBI_D_Cat ~Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI + Extrav_NEOFFI + Apert_NEOFFI, 
              family = binomial(link = "logit"), 
              data = MBI_D_MA)

coeficientes2 <- coef(modelo_logitD)


# Ordenar los coeficientes por valor absoluto
coef_ordenados2 <- coeficientes2[order(abs(coeficientes2), decreasing = TRUE)]

# Mostrar los coeficientes ordenados
print("Coeficientes beta ordenados por valor absoluto:")
print(coef_ordenados2)
```
Como puede observarse, el coeficiente con mayor valor absoluto se trata del asociado a la variable independiente Responsabilidad tomando un valor de $\beta$=-0.084439394. Esto sugiere que la Responsabilidad es la variable con mayor fuerza a la hora de clasificar entre la Despersonalización Media y Alta.

Para la Realización Personal:
```{r}
modelo_logitRP <- glm(MBI_RP_Cat ~Neur_NEOFFI + Amab_NEOFFI + Resp_NEOFFI + Extrav_NEOFFI + Apert_NEOFFI, 
              family = binomial(link = "logit"), 
              data = MBI_RP_BM)

coeficientes3 <- coef(modelo_logitRP)

# Ordenar los coeficientes por valor absoluto
coef_ordenados3 <- coeficientes3[order(abs(coeficientes3), decreasing = TRUE)]

# Mostrar los coeficientes ordenados
print("Coeficientes beta ordenados por valor absoluto:")
print(coef_ordenados3)
```
Como puede observarse, el coeficiente con mayor valor absoluto se trata del asociado a la variable independiente Neuroticismo tomando un valor de $\beta$=0.04803630. Esto sugiere que el Neuroticismo es la variable con mayor fuerza a la hora de clasificar entre la Realización Personal Media y Baja. Además, la Amabilidad también tiene una fuerza significativa con un valor de coeficiente muy cercano al del Neuroticismo ($\beta$=-0.03903669).

Una vez que disponemos del modelo se procede a comprobar su funcionamiento. Para ello, se obtienen las matrices de confusión que permiten comparar las predicciones del modelo con los resultados reales y evaluar cómo de bien está funcionando el modelo a clasificar los datos en las categorías correctas. 

Para el caso del Cansancio Emocional:
```{r}
# Generar predicciones (probabilidades)
predicciones_prob <- predict(modelo_logitCE, type = "response")

# Convertir probabilidades en predicciones binarias (umbral = 0.5)
predicciones_binarias <- ifelse(predicciones_prob >= 0.5, 1, 0)

# Crear la matriz de confusión
matriz_confusion <- table(Prediccion = predicciones_binarias, Real = MBI_CE_MA$MBI_CE_Cat)

# Mostrar la matriz de confusión
print("Matriz de confusión:")
print(matriz_confusion)
```
El modelo predijo correctamente que el individuo tenía Cansancio emocional 40 veces, que el individuo tenía Cansancio Emocional cuando en realidad no lo tenía 19 veces, que el individuo no tenía Cansancio Emocional cuando en realidad sí lo tenía 24 veces y predijo correctamente que el individuo no tenía Cansancio Emocional 57 veces. 

Para el caso de la Despersonalización:
```{r}
# Generar predicciones (probabilidades)
predicciones_prob <- predict(modelo_logitD, type = "response")

# Convertir probabilidades en predicciones binarias (umbral = 0.5)
predicciones_binarias <- ifelse(predicciones_prob >= 0.5, 1, 0)

# Crear la matriz de confusión
matriz_confusion <- table(Prediccion = predicciones_binarias, Real = MBI_D_MA$MBI_D_Cat)

# Mostrar la matriz de confusión
print("Matriz de confusión:")
print(matriz_confusion)
```
El modelo predijo correctamente que el individuo tenía Despersonalización 50 veces, que el individuo tenía Despersonalización cuando en realidad no la tenía 21 veces, que el individuo no tenía Despersonalización cuando en realidad sí la tenía 23 veces y predijo correctamente que el individuo no tenía Despersonalización 77 veces. 

Para el caso de la Realización Personal:
```{r}
# Generar predicciones (probabilidades)
predicciones_prob <- predict(modelo_logitRP, type = "response")

# Convertir probabilidades en predicciones binarias (umbral = 0.5)
predicciones_binarias <- ifelse(predicciones_prob >= 0.5, 1, 0)

# Crear la matriz de confusión
matriz_confusion <- table(Prediccion = predicciones_binarias, Real = MBI_RP_BM$MBI_RP_Cat)

# Mostrar la matriz de confusión
print("Matriz de confusión:")
print(matriz_confusion)
```
El modelo predijo correctamente que el individuo tenía Realización Personal 83 veces, que el individuo tenía Realización Personal cuando en realidad no la tenía 44 veces, que el individuo no tenía Realización Personal cuando en realidad sí la tenía 22 veces y predijo correctamente que el individuo no tenía Realización Personal 34 veces. 

A continuación, se calculará el training error del modelo. Este error muestra la proporción de predicciones incorrectas que el modelo realiza sobre el conjunto de los datos de entrenamiento.

Para el caso del Cansancio Emocional:
```{r}
# Calcular las predicciones binarias usando el modelo entrenado
predicciones_binarias <- ifelse(predict(modelo_logitCE, type = "response") >= 0.5, 1, 0)

# Calcular el training error (proporción de predicciones incorrectas)
training_error <- mean(predicciones_binarias != MBI_CE_MA$MBI_CE_Cat)

# Mostrar el training error
cat("Training Error del modelo:", training_error*100, "(%)\n")

```

Para el caso de la Despersonalización:
```{r}
# Calcular las predicciones binarias usando el modelo entrenado
predicciones_binarias <- ifelse(predict(modelo_logitD, type = "response") >= 0.5, 1, 0)

# Calcular el training error (proporción de predicciones incorrectas)
training_error <- mean(predicciones_binarias != MBI_D_MA$MBI_D_Cat)

# Mostrar el training error
cat("Training Error del modelo:", training_error*100, "(%)\n")

```

Para el caso de la Realización Personal:
```{r}
# Calcular las predicciones binarias usando el modelo entrenado
predicciones_binarias <- ifelse(predict(modelo_logitRP, type = "response") >= 0.5, 1, 0)

# Calcular el training error (proporción de predicciones incorrectas)
training_error <- mean(predicciones_binarias != MBI_RP_BM$MBI_RP_Cat)

# Mostrar el training error
cat("Training Error del modelo:", training_error*100, "(%)\n")

```

Como puede comprobarse, los training errors tanto para el modelo lineal como para el modelo de regresión logística son muy similares. Este hecho implica que ambos modelos están capturando la misma relación y por tanto realizando predcciones similares.

Finalmente, se calculará el p-valor de las variables independientes de personalidad. Este nos permitirá determinar la significancia estadística de los resultados obtenidos en el análisis de datos, midiendo la fuerza de la evidencia en contra de la hipótesis nula. Cuanto más pequeño sea el p-valor, más evidencia habrá para rechazar la hipótesis nula. En nuesto caso, la hipótesis nula es que la variable independiente asociada a cada coeficiente del modelo no tiene efecto significativo sobre la variable dependiente. Se ha considerado un nivel de confianza del 95%

Cuando el p-valor es menor que 0.05, se rechaza la hipótesis nula, lo que implica que el coeficiente $\beta_i$ es significativo en el modelo. Si el p-valor es mayor que 0.05, no se puede rechazar la hipótesis nula.

Cálculo de los p-valores para el Cansancio Emocional:
```{r}
# Resumen del modelo logístico
summary_modelo <- summary(modelo_logitCE)

# Mostrar los valores p
p_valores <- summary_modelo$coefficients[, "Pr(>|z|)"]

# Mostrar todos los valores p
print("Valores p de los coeficientes:")
print(p_valores)


```
En este caso, las variables significativas serían el Neuroticismo y la Extraversión.

Cálculo de los p-valores para la Despersonalización:
```{r}
# Resumen del modelo logístico
summary_modelo <- summary(modelo_logitD)

# Mostrar los valores p
p_valores <- summary_modelo$coefficients[, "Pr(>|z|)"]

# Mostrar todos los valores p
print("Valores p de los coeficientes:")
print(p_valores)


```
En este caso, las variables significativas serían el Neuroticismo y la Responsabilidad.

Cálculo de los p-valores para la Realización Personal:
```{r}
# Resumen del modelo logístico
summary_modelo <- summary(modelo_logitRP)

# Mostrar los valores p
p_valores <- summary_modelo$coefficients[, "Pr(>|z|)"]

# Mostrar todos los valores p
print("Valores p de los coeficientes:")
print(p_valores)


```
En este caso, la única variable significativa sería el Neuroticismo. 
